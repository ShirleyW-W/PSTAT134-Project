


import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.svm import SVC
from sklearn.svm import LinearSVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer

import warnings
 
warnings.filterwarnings(action='ignore')








# import the data
fake_news = pd.read_csv("/Users/elliehuang/Desktop/pstat_134/archive (1)/Fake.csv")
true_news = pd.read_csv("/Users/elliehuang/Desktop/pstat_134/archive (1)/True.csv")

# view first few rows for each 
print(fake_news.head())
print(true_news.head())


# add labels
fake_news["label"] = "Fake"
true_news["label"] = "True"

# combine the two separate dataframes
news_df = pd.concat([fake_news, true_news], ignore_index = True)





import string

# checking for missing values
print(news_df.isna().sum())

# converting letters to lowercase
news_df["text"] = news_df["text"].str.lower()

# removing punctuation
news_df["text"] = news_df["text"].str.replace("[{}]".format(string.punctuation), "", regex = True)

# removing other special characters
news_df["text"] = news_df["text"].apply(lambda x: x.encode("ascii", "ignore").decode("utf-8"))

# view cleaned dataset
print(news_df.head())


# tokenizing article text into words
tokenized_news = [nltk.word_tokenize(article) for article in news_df["text"]]


# removing stopwords
stop_words = set(stopwords.words("english"))

cleaned_articles = [[word for word in article if word not in stop_words] 
    for article in tokenized_news]

news_df["text"] = [" ".join(article) for article in cleaned_articles]
print((news_df["text"].head()))








from collections import Counter
all_words = [word for article in cleaned_articles for word in article]
word_counts = Counter(all_words)

common_words = word_counts.most_common(25) 
words, counts = zip(*common_words)

plt.figure(figsize = (8,5))
plt.bar(words, counts)
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.title("Most Commonly Occurring Words (Excluding Stop Words)")
plt.xticks(rotation = 45)
plt.show()





fake_articles = news_df[news_df.label == "Fake"]
fake_tokenized = [nltk.word_tokenize(article) for article in fake_articles["text"]]
fake_cleaned = [[word for word in article if word not in stop_words] 
    for article in fake_tokenized]
fake_words = [word for article in fake_cleaned for word in article]

true_articles = news_df[news_df.label == "True"]
true_tokenized = [nltk.word_tokenize(article) for article in true_articles["text"]]
true_cleaned = [[word for word in article if word not in stop_words] 
    for article in true_tokenized]
true_words = [word for article in true_cleaned for word in article]

fake_word_counts = Counter(fake_words)
true_word_counts = Counter(true_words)

fake_most_common = fake_word_counts.most_common(25) 
fake_words, fake_counts = zip(*fake_most_common)
true_most_common = true_word_counts.most_common(25) 
true_words, true_counts = zip(*true_most_common)

# plotting most common words in true articles
plt.figure(figsize = (8, 5))
plt.bar(true_words, true_counts, color="green")
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.title("Most Common Words in True News")
plt.xticks(rotation = 45)
plt.show()

# plotting most common words in fake articles
plt.figure(figsize = (8, 5))
plt.bar(fake_words, fake_counts, color="red")
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.title("Most Common Words in Fake News")
plt.xticks(rotation = 45)
plt.show()








import re
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from textblob import Word

# create dictionaries for word frequencies
fake_top_words = dict(fake_word_counts.most_common(50))
true_top_words = dict(true_word_counts.most_common(50))

# merge word counts while keeping track of origins
combined_word_counts = {word: fake_top_words.get(word, 0) + true_top_words.get(word, 0)
                        for word in set(fake_top_words) | set(true_top_words)}

# custom function to color words based on their origin
def color_func(word, font_size, position, orientation, random_state=None, **kwargs):
    if word in fake_top_words and word in true_top_words:
        return "rgb(128, 128, 128)"  # gray for shared words
    elif word in fake_top_words:
        return "rgb(255, 0, 0)"  # red for fake news words
    elif word in true_top_words:
        return "rgb(0, 128, 0)"  # green for true news words
    return "rgb(0, 0, 0)"  

# generate word cloud
wordcloud = WordCloud(
    width = 900, height = 450, max_words = 100, background_color = "white"
).generate_from_frequencies(combined_word_counts)

# apply custom coloring 
wordcloud.recolor(color_func = color_func)
 
# plotting the wordcloud
plt.figure(figsize = (8, 5))
plt.imshow(wordcloud, interpolation = "bilinear")
plt.axis("off")
plt.title("Top 100 Words in Fake & True News", fontsize = 16, fontweight = "bold")
plt.show()





from nltk.util import bigrams

def extract_bigrams(text):
    words = [word for word in nltk.word_tokenize(text.lower()) if word.isalnum() and word not in stop_words]
    return list(bigrams(words))

# Extract bigrams from each review
all_bigrams = []
for article in news_df["text"]:
    all_bigrams.extend(extract_bigrams(article))

# Convert bigrams to string format
bigram_strings = [" ".join(bigram) for bigram in all_bigrams]

# Count bigrams
bigram_counts = Counter(bigram_strings)

# Get top 30 bigrams
top_bigrams = pd.DataFrame(bigram_counts.most_common(30), columns=["bigram", "count"])
print(top_bigrams.head())


from itertools import islice
import networkx as nx
from nltk.tokenize import word_tokenize

# function to process bigrams

def get_top_bigrams(df, label, top_n = 30):
    stop_words = set(stopwords.words('english'))
    
    df = df[df['label'] == label]
    
    bigrams = []
    for text in df['text'].dropna():  # remove na values
        words = [word.lower() for word in word_tokenize(str(text)) if word.isalpha()]
        words = [word for word in words if word not in stop_words and len(word) > 2]  # remove stopwords
        bigrams.extend(zip(words, islice(words, 1, None)))  # create bigrams
        
    bigram_counts = Counter(bigrams)
    
    # select only the top n bigrams
    top_bigrams = dict(bigram_counts.most_common(top_n))
    
    return top_bigrams

# get top 30 bigrams for TRUE and FAKE news
true_bigrams = get_top_bigrams(news_df, "True", top_n=30)
fake_bigrams = get_top_bigrams(news_df, "Fake", top_n=30)

# function to plot bigram graph
def plot_bigram_graph(bigrams, title, color):
    G = nx.DiGraph()
    
    for (word1, word2), count in bigrams.items():
        G.add_edge(word1, word2, weight = count)
    
    plt.figure(figsize = (12, 8))
    pos = nx.spring_layout(G, k = 1.5) 
    edges = G.edges(data = True)
    
    nx.draw(G, pos, node_color = color, edge_color = 'gray', with_labels = True, 
            node_size = 600, font_size = 12) 
    
    # draw edge labels (weights)
    nx.draw_networkx_edge_labels(G, pos, edge_labels={(u, v): d['weight'] for u, v, d in edges}, 
                                 font_size = 12) 
    
    plt.title(title, fontsize = 18, fontweight = "bold") 
    plt.show()

# plot true news bigram graph
plot_bigram_graph(true_bigrams, "Frequent Bigrams in True News", color = "lightgreen")

# plot fake news bigram graph
plot_bigram_graph(fake_bigrams, "Frequent Bigrams in Fake News", color = "pink")











# data pre-processing
corpus = news_df["text"]
tokenized_corpus = [simple_preprocess(sentence) for sentence in corpus]

stop_words = set(stopwords.words('english'))  # NLTK stop words

filtered_corpus = [
    [word for word in sentence if word.lower() not in stop_words]
    for sentence in tokenized_corpus
]

X = news_df["text"]
y = news_df["label"]

# splitting into testing and training sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 20, stratify = y)


# Initialize the TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer()

# Fit and transform the training data
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Transform the test data (no fitting on test data)
X_test_tfidf = tfidf_vectorizer.transform(X_test)





# Train logistic regression model
clf_tfidf = LogisticRegression()
clf_tfidf.fit(X_train_tfidf, y_train)

# Predict on test data
y_pred_lr_tfidf = clf_tfidf.predict(X_test_tfidf)

# Evaluate accuracy
accuracy_lr_tfidf = accuracy_score(y_test, y_pred_lr_tfidf)





# Initialize the SVM classifier
svm_model = SVC(kernel='linear')

# Fit the SVM model on the TF-IDF transformed training data
svm_model.fit(X_train_tfidf, y_train)

# Predict on the test set
y_pred_svm_tfidf = svm_model.predict(X_test_tfidf)

# Evaluate accuracy
accuracy_svm_tfidf = accuracy_score(y_test, y_pred_svm_tfidf)

print(f"The accuracy for Logistic Regression is {accuracy_lr_tfidf: .4f}, the accuracy for SVM Linear is {accuracy_svm_tfidf: .4f}.")








model_cbow = Word2Vec(sentences=filtered_corpus, vector_size=100, window=5, min_count=1, workers=4, sg=0)
model_sg = Word2Vec(sentences=filtered_corpus, vector_size=100, window=5, min_count=1, workers=4, sg=1)

# Parameters:
# - vector_size: Dimensionality of word embeddings
# - window: Context window size
# - min_count: Ignores words appearing less than min_count times
# - workers: Number of CPU cores to use
# - sg: 0 for CBOW (Continuous Bag of Words), 1 for Skip-gram

model_cbow.save("word2vec_cbow.model")
model_sg.save("word2vec_sg.model")





# Load the model
cbow = Word2Vec.load("word2vec_cbow.model")

def sentence_to_vector(sentence, model):
    """Convert a sentence to a vector by averaging word embeddings."""
    words = simple_preprocess(sentence)  # Tokenization
    word_vectors = [model.wv[word] for word in words if word in model.wv]

    if word_vectors:
        return np.mean(word_vectors, axis=0)  # Average word vectors
    else:
        return np.zeros(model.vector_size)  # Return a zero vector if no words are in the model

X_vectors_cbow = np.array([sentence_to_vector(sentence, cbow) for sentence in X])

# train-test split
X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_vectors_cbow, y, test_size = 0.25, random_state = 20, stratify = y)





# Train logistic regression model
clf_cbow = LogisticRegression()
clf_cbow.fit(X_train_cbow, y_train)

# Predict on test data
y_pred_lr_cbow = clf_cbow.predict(X_test_cbow)

# Evaluate accuracy
accuracy_lr_cbow = accuracy_score(y_test, y_pred_lr_cbow)
print(f"Logistic Accuracy: {accuracy_lr_cbow:.4f}")





# Train Linear SVM model
svm_cbow_model = SVC(kernel="linear")
svm_cbow_model.fit(X_train_cbow, y_train)

# Predict on test data
y_pred_svm_cbow = svm_cbow_model.predict(X_test_cbow)

# Evaluate accuracy
accuracy_svm_cbow = accuracy_score(y_test, y_pred_svm_cbow)

print(f"The accuracy for Logistic Regression is {accuracy_lr_cbow: .4f}, the accuracy for SVM Linear is {accuracy_svm_cbow: .4f}.")





sg = Word2Vec.load("word2vec_sg.model")

X_vectors_sg = np.array([sentence_to_vector(sentence, sg) for sentence in X])

# train-test split
X_train_sg, X_test_sg, y_train, y_test = train_test_split(X_vectors_sg, y, test_size = 0.25, random_state = 20, stratify = y)





# Train logistic regression model
clf_sg = LogisticRegression()
clf_sg.fit(X_train_sg, y_train)

# Predict on test data
y_pred_lr_sg = clf_sg.predict(X_test_sg)

# Evaluate accuracy
accuracy_lr_sg = accuracy_score(y_test, y_pred_lr_sg)





# Train Linear SVM model
svm_model_sg = SVC(kernel="linear")
svm_model_sg.fit(X_train_sg, y_train)

# Predict on test data
y_pred_svm_sg = svm_model_sg.predict(X_test_sg)

# Evaluate accuracy
accuracy_svm_sg = accuracy_score(y_test, y_pred_svm_sg)

print(f"The accuracy for Logistic Regression is {accuracy_lr_sg: .4f}, the accuracy for SVM Linear is {accuracy_svm_sg: .4f}.")





# tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(corpus)

# define function for loading GloVe embeddings
def load_glove_embeddings(filepath, word_index, embedding_dim):
    vocab_size = len(word_index) + 1
    embedding_matrix = np.zeros((vocab_size, embedding_dim))
    
    with open(filepath, encoding="utf8") as f:
        for line in f:
            word, *vector = line.split()
            if word in word_index:
                idx = word_index[word]
                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]
    
    return embedding_matrix

embedding_dim = 50
embedding_matrix = load_glove_embeddings('/Users/elliehuang/Desktop/pstat_134/FinalProject/glove.6B/glove.6B.50d.txt', tokenizer.word_index, embedding_dim)

# define function for converting text to embedding representation
def text_to_embedding(text, tokenizer, embedding_matrix, embedding_dim):
    words = text.split()
    word_indices = [tokenizer.word_index[word] for word in words if word in tokenizer.word_index]
    
    if len(word_indices) == 0:
        return np.zeros(embedding_dim)  # return zero vector if no words found
    
    # average word embeddings
    embeddings = np.array([embedding_matrix[idx] for idx in word_indices])
    return np.mean(embeddings, axis=0)

X_vectors_glove = np.array([text_to_embedding(text, tokenizer, embedding_matrix, embedding_dim) for text in corpus])

# train-test split
X_train_glove, X_test_glove, y_train, y_test = train_test_split(X_vectors_glove, y, test_size = 0.25, random_state = 20, stratify = y)

# encode labels
label_encoder = LabelEncoder()
y_glove = label_encoder.fit_transform(news_df["label"])
print(label_encoder.classes_)  





# train a Logistic Regression model
log_reg_model = LogisticRegression(max_iter=1000) 
log_reg_model.fit(X_train_glove, y_train)

# make predictions
y_pred_lr_glove = log_reg_model.predict(X_test_glove)

# evaluate model performance
accuracy_lr_glove = accuracy_score(y_test, y_pred_lr_glove)






# train SVM model
svm_model = SVC(kernel='linear')
svm_model.fit(X_train_glove, y_train)

# make predictions
y_pred_svm_glove = svm_model.predict(X_test_glove)

# evaluate model
accuracy_svm_glove = accuracy_score(y_test, y_pred_svm_glove)

print(f"The accuracy for Logistic Regression is {accuracy_lr_glove: .4f}, the accuracy for SVM Linear is {accuracy_svm_glove: .4f}.")





# creating dataframe for accuracy scores
accuracy_df = pd.DataFrame({
    "Logistic Regression": [accuracy_lr_tfidf, accuracy_lr_sg, accuracy_lr_cbow, accuracy_lr_glove],
    "SVM": [accuracy_svm_tfidf, accuracy_svm_sg, accuracy_svm_cbow, accuracy_svm_glove]
}, index=["TF-IDF", "CBOW", "Skip-gram", "GloVe"])

print(accuracy_df)

# precision
precision_lr_tfidf = precision_score(y_test, y_pred_lr_tfidf, average='macro')
precision_lr_cbow = precision_score(y_test, y_pred_lr_cbow, average='macro')
precision_lr_sg = precision_score(y_test, y_pred_lr_sg, average='macro')
precision_lr_glove = precision_score(y_test, y_pred_lr_glove, average='macro')

# recall
recall_lr_tfidf = recall_score(y_test, y_pred_lr_tfidf, average='macro')
recall_lr_cbow = recall_score(y_test, y_pred_lr_cbow, average='macro')
recall_lr_sg = recall_score(y_test, y_pred_lr_sg, average='macro')
recall_lr_glove = recall_score(y_test, y_pred_lr_glove, average='macro')

# f1-score
f1_lr_tfidf = f1_score(y_test, y_pred_lr_tfidf, average='macro')
f1_lr_cbow = f1_score(y_test, y_pred_lr_cbow, average='macro')
f1_lr_sg = f1_score(y_test, y_pred_lr_sg, average='macro')
f1_lr_glove = f1_score(y_test, y_pred_lr_glove, average='macro')

# store them in lists
accuracy_scores = [accuracy_lr_tfidf, accuracy_lr_cbow, accuracy_lr_sg, accuracy_lr_glove]
precision_scores = [precision_lr_tfidf, precision_lr_cbow, precision_lr_sg, precision_lr_glove]
recall_scores = [recall_lr_tfidf, recall_lr_cbow, recall_lr_sg, recall_lr_glove]
f1_scores = [f1_lr_tfidf, f1_lr_cbow, f1_lr_sg, f1_lr_glove]

models = ["TF-IDF", "CBOW", "Skip-gram", "GloVe"]

# create subplots
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle("Evaluation Metrics for Logistic Regression Models", fontsize=16)

# plot Accuracy
axes[0, 0].bar(models, accuracy_scores, color='blue')
axes[0, 0].set_title("Accuracy")
axes[0, 0].set_ylim(0, 1)
axes[0, 0].grid(axis='y', linestyle='--', alpha=0.7)

# plot Precision
axes[0, 1].bar(models, precision_scores, color='orange')
axes[0, 1].set_title("Precision")
axes[0, 1].set_ylim(0, 1)
axes[0, 1].grid(axis='y', linestyle='--', alpha=0.7)

# plot Recall
axes[1, 0].bar(models, recall_scores, color='green')
axes[1, 0].set_title("Recall")
axes[1, 0].set_ylim(0, 1)
axes[1, 0].grid(axis='y', linestyle='--', alpha=0.7)

# plot F1-Score
axes[1, 1].bar(models, f1_scores, color='red')
axes[1, 1].set_title("F1-Score")
axes[1, 1].set_ylim(0, 1)
axes[1, 1].grid(axis='y', linestyle='--', alpha=0.7)

# adjust layout for better spacing
plt.tight_layout(rect=[0, 0, 1, 0.96])

# show plot
plt.show()




{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = pd.read_csv(\"Fake.csv\")\n",
    "true_news = pd.read_csv(\"True.csv\")\n",
    "# add labels\n",
    "fake_news[\"label\"] = \"Fake\"\n",
    "true_news[\"label\"] = \"True\"\n",
    "\n",
    "# combine the two separate dataframes\n",
    "full_data = pd.concat([fake_news, true_news], ignore_index = True)\n",
    "corpus = full_data[\"text\"]\n",
    "tokenized_corpus = [simple_preprocess(sentence) for sentence in corpus]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))  # NLTK stop words\n",
    "\n",
    "filtered_corpus = [\n",
    "    [word for word in sentence if word.lower() not in stop_words]\n",
    "    for sentence in tokenized_corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date label  \n",
       "0  December 31, 2017  Fake  \n",
       "1  December 31, 2017  Fake  \n",
       "2  December 30, 2017  Fake  \n",
       "3  December 29, 2017  Fake  \n",
       "4  December 25, 2017  Fake  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and Save Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a word embedding technique that uses shallow neural networks to map words to vectors such that similar words are closer together. This ensures that the semantic meaning is captured by the embedding since words with similar meanings have similar vector representations. There are two main models that fall under Word2Vec: continuous bag of words (CBOW) and skip-gram.\n",
    "\n",
    "CBOW predicts the target words based on its surrounding context. Given an input of surrounding words within a certain window of the target word, the model predicts the target word.\n",
    "\n",
    "Skip-gram is the reverse of CBOW. Given a word, the model determines what the surrounding context is. We tried both embedding techniques to determine which one would enhance performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = Word2Vec(sentences=filtered_corpus, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "model_sg = Word2Vec(sentences=filtered_corpus, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Parameters:\n",
    "# - vector_size: Dimensionality of word embeddings\n",
    "# - window: Context window size\n",
    "# - min_count: Ignores words appearing less than min_count times\n",
    "# - workers: Number of CPU cores to use\n",
    "# - sg: 0 for CBOW (Continuous Bag of Words), 1 for Skip-gram\n",
    "\n",
    "model_cbow.save(\"word2vec_cbow.model\")\n",
    "model_sg.save(\"word2vec_sg.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "cbow = Word2Vec.load(\"word2vec_cbow.model\")\n",
    "\n",
    "def sentence_to_vector(sentence, model):\n",
    "    \"\"\"Convert a sentence to a vector by averaging word embeddings.\"\"\"\n",
    "    words = simple_preprocess(sentence)  # Tokenization\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)  # Average word vectors\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words are in the model\n",
    "\n",
    "X = full_data[\"text\"]\n",
    "y = full_data[\"label\"]\n",
    "\n",
    "X_vectors = np.array([sentence_to_vector(sentence, cbow) for sentence in X])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size = 0.25, random_state = 20, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM With Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Linear SVM Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = Word2Vec.load(\"word2vec_sg.model\")\n",
    "\n",
    "X_vectors_sg = np.array([sentence_to_vector(sentence, sg) for sentence in X])\n",
    "\n",
    "X_train_sg, X_test_sg, y_train_sg, y_test_sg = train_test_split(X_vectors_sg, y, test_size = 0.25, random_state = 20, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "clf_sg = LogisticRegression()\n",
    "clf_sg.fit(X_train_sg, y_train_sg)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_sg = clf_sg.predict(X_test_sg)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_sg = accuracy_score(y_test_sg, y_pred_sg)\n",
    "print(f\"Logistic Accuracy: {accuracy_sg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM With Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train Linear SVM model\n",
    "svm_model_sg = LinearSVC()\n",
    "svm_model_sg.fit(X_train_sg, y_train_sg)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_sg = svm_model_sg.predict(X_test_sg)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_sg = accuracy_score(y_test_sg, y_pred_sg)\n",
    "print(f\"Linear SVM Accuracy: {accuracy_sg:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
